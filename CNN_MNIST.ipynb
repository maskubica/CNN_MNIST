{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/michal/Programming/Python/DL-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available!\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU Available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu',input_shape=(28,28,1)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training first CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/13\n",
      "60000/60000 [==============================] - 52s 871us/step - loss: 0.2488 - acc: 0.9244 - val_loss: 0.0512 - val_acc: 0.9828\n",
      "Epoch 2/13\n",
      "60000/60000 [==============================] - 48s 802us/step - loss: 0.0850 - acc: 0.9755 - val_loss: 0.0376 - val_acc: 0.9874\n",
      "Epoch 3/13\n",
      "60000/60000 [==============================] - 48s 803us/step - loss: 0.0654 - acc: 0.9805 - val_loss: 0.0354 - val_acc: 0.9881\n",
      "Epoch 4/13\n",
      "60000/60000 [==============================] - 48s 802us/step - loss: 0.0520 - acc: 0.9840 - val_loss: 0.0333 - val_acc: 0.9885\n",
      "Epoch 5/13\n",
      "60000/60000 [==============================] - 48s 803us/step - loss: 0.0449 - acc: 0.9862 - val_loss: 0.0303 - val_acc: 0.9903\n",
      "Epoch 6/13\n",
      "60000/60000 [==============================] - 48s 803us/step - loss: 0.0383 - acc: 0.9879 - val_loss: 0.0313 - val_acc: 0.9908\n",
      "Epoch 7/13\n",
      "60000/60000 [==============================] - 48s 804us/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0297 - val_acc: 0.9907\n",
      "Epoch 8/13\n",
      "60000/60000 [==============================] - 46s 770us/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0275 - val_acc: 0.9916\n",
      "Epoch 9/13\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.0286 - val_acc: 0.9910\n",
      "Epoch 10/13\n",
      "60000/60000 [==============================] - 50s 840us/step - loss: 0.0261 - acc: 0.9915 - val_loss: 0.0312 - val_acc: 0.9912\n",
      "Epoch 11/13\n",
      "60000/60000 [==============================] - 49s 809us/step - loss: 0.0245 - acc: 0.9924 - val_loss: 0.0270 - val_acc: 0.9915\n",
      "Epoch 12/13\n",
      "60000/60000 [==============================] - 47s 783us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0274 - val_acc: 0.9922\n",
      "Epoch 13/13\n",
      "60000/60000 [==============================] - 49s 817us/step - loss: 0.0209 - acc: 0.9926 - val_loss: 0.0281 - val_acc: 0.9927\n",
      "Test loss: 0.02806220381980488\n",
      "Test accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=13,\n",
    "          verbose=True,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               991360    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,044,234\n",
      "Trainable params: 1,044,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=(3,3), activation = 'relu',input_shape=(28,28,1)))\n",
    "model.add(layers.Convolution2D(64, (5, 5), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training second CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 47s 789us/step - loss: 0.1813 - acc: 0.9440 - val_loss: 0.0440 - val_acc: 0.9858\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 46s 769us/step - loss: 0.0619 - acc: 0.9817 - val_loss: 0.0358 - val_acc: 0.9886\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 43s 723us/step - loss: 0.0428 - acc: 0.9867 - val_loss: 0.0269 - val_acc: 0.9911\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 45s 757us/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0276 - val_acc: 0.9906\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 43s 711us/step - loss: 0.0287 - acc: 0.9908 - val_loss: 0.0251 - val_acc: 0.9920\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.0213 - acc: 0.9935 - val_loss: 0.0262 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 43s 724us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0261 - val_acc: 0.9921\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 44s 727us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0277 - val_acc: 0.9919\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 43s 718us/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0328 - val_acc: 0.9920\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 42s 702us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0351 - val_acc: 0.9913\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 42s 701us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.0373 - val_acc: 0.9905\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 42s 700us/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0271 - val_acc: 0.9932\n",
      "Test loss: 0.027084069931217754\n",
      "Test accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=True,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
